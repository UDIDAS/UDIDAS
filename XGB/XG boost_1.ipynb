{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16162 entries, 0 to 16161\n",
      "Data columns (total 11 columns):\n",
      "Unnamed: 0               16162 non-null int64\n",
      "ID                       16162 non-null int64\n",
      "Type                     16162 non-null object\n",
      "event_timestamp          16162 non-null int64\n",
      "event_label              16162 non-null object\n",
      "log_timestamp            16162 non-null int64\n",
      "log_reading_1            15848 non-null float64\n",
      "log_reading_2            15883 non-null object\n",
      "log_reading_3            15843 non-null float64\n",
      "log_reading_4            16162 non-null int64\n",
      "warranty_service_flag    1389 non-null object\n",
      "dtypes: float64(2), int64(5), object(4)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('C:/Users/udipt/Desktop/Websoft/Assignment/DataScienceCaseStudy/dataSample.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'ID', 'event_timestamp', 'log_timestamp', 'log_reading_1',\n",
       "       'log_reading_3', 'log_reading_4', 'Type_TypeA', 'Type_TypeB',\n",
       "       'event_label_activate', 'event_label_break', 'log_reading_2_a',\n",
       "       'log_reading_2_b', 'log_reading_2_c', 'warranty_service_flag_n',\n",
       "       'warranty_service_flag_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.get_dummies(df)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16162 entries, 0 to 16161\n",
      "Data columns (total 13 columns):\n",
      "ID                         16162 non-null int64\n",
      "event_timestamp            16162 non-null int64\n",
      "log_timestamp              16162 non-null int64\n",
      "log_reading_1              15848 non-null float64\n",
      "log_reading_3              15843 non-null float64\n",
      "log_reading_4              16162 non-null int64\n",
      "Type_TypeA                 16162 non-null uint8\n",
      "Type_TypeB                 16162 non-null uint8\n",
      "event_label_break          16162 non-null uint8\n",
      "log_reading_2_a            16162 non-null uint8\n",
      "log_reading_2_b            16162 non-null uint8\n",
      "log_reading_2_c            16162 non-null uint8\n",
      "warranty_service_flag_y    16162 non-null uint8\n",
      "dtypes: float64(2), int64(4), uint8(7)\n",
      "memory usage: 868.2 KB\n"
     ]
    }
   ],
   "source": [
    "df=df.drop(columns=['warranty_service_flag_n','event_label_activate','Unnamed: 0'],axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_reading_1'].fillna(df['log_reading_1'].median(),inplace=True)\n",
    "df['log_reading_3'].fillna(df['log_reading_3'].median(),inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3414800148496473\n"
     ]
    }
   ],
   "source": [
    "x=df.drop('event_label_break',axis=1)\n",
    "y=df['event_label_break']\n",
    "print(y.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11313, 12)---(4849, 12)---(11313,)---(4849,)---0.3414655705825157---0.3415137141678697\n"
     ]
    }
   ],
   "source": [
    "x_tr,x_te,y_tr,y_te=train_test_split(x,y,test_size=.3,stratify=y,random_state=10)\n",
    "print(x_tr.shape,x_te.shape,y_tr.shape,y_te.shape,y_tr.mean(),y_te.mean(),sep='---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.34, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=-1, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=10, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg=xgb.XGBClassifier(base_score=.34,n_jobs=-1,random_state=10)\n",
    "xg.fit(x_tr,y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The custom model predicts 37.76% points as positive\n"
     ]
    }
   ],
   "source": [
    "print(f'The custom model predicts {xg.predict(x_te).mean()*100:.2f}% points as positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=XGBClassifier(base_score=0.34, booster='gbtree',\n",
       "                                     colsample_bylevel=1, colsample_bynode=1,\n",
       "                                     colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "                                     importance_type='gain',\n",
       "                                     interaction_constraints='',\n",
       "                                     learning_rate=0.300000012,\n",
       "                                     max_delta_step=0, max_depth=6,\n",
       "                                     min_child_weight=1, missing=nan,\n",
       "                                     monotone_constraints='()',\n",
       "                                     n_est...rs=100, n_jobs=-1,\n",
       "                                     num_parallel_tree=1,\n",
       "                                     objective='binary:logistic',\n",
       "                                     random_state=10, reg_alpha=0, reg_lambda=1,\n",
       "                                     scale_pos_weight=1, subsample=1,\n",
       "                                     tree_method='exact', validate_parameters=1,\n",
       "                                     verbosity=None),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'n_estimators': range(200, 251, 10)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg={'n_estimators':range(200,251,10)}\n",
    "xg_gr=GridSearchCV(xg,pg,cv=5,n_jobs=-1,scoring='roc_auc')\n",
    "xg_gr.fit(x_tr,y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are {'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "print(f'Best parameters are {xg_gr.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model predicts 36.21% points as positive\n"
     ]
    }
   ],
   "source": [
    "xg_gb=xg_gr.best_estimator_\n",
    "y_pro=xg_gb.predict_proba(x_te)\n",
    "y_pre=xg_gb.predict(x_te)\n",
    "print(f'The model predicts {y_pre.mean()*100:.2f}% points as positive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.42025554,\n",
       " 0.0016267279,\n",
       " 0.0041177203,\n",
       " 0.098133914,\n",
       " 0.34862465,\n",
       " 0.0018365277,\n",
       " 0.458429,\n",
       " 0.72252584,\n",
       " 0.0059563913,\n",
       " 0.99586546,\n",
       " 0.01722325,\n",
       " 0.0067896037,\n",
       " 0.07148429,\n",
       " 0.009459116,\n",
       " 0.26290563,\n",
       " 0.64070845,\n",
       " 0.011807912,\n",
       " 0.20231637,\n",
       " 0.0015888875,\n",
       " 0.45999336,\n",
       " 0.013321938,\n",
       " 0.8604137,\n",
       " 0.6381177,\n",
       " 0.8114269,\n",
       " 0.57082725,\n",
       " 0.5713725,\n",
       " 0.0015670238,\n",
       " 0.64506817,\n",
       " 0.51694113,\n",
       " 0.029473884,\n",
       " 0.679631,\n",
       " 0.7734546,\n",
       " 0.008556421,\n",
       " 0.73107016,\n",
       " 0.007744525,\n",
       " 0.019005701,\n",
       " 0.0018353341,\n",
       " 0.0048465068,\n",
       " 0.986652,\n",
       " 0.0019886843,\n",
       " 0.001981088,\n",
       " 0.6337368,\n",
       " 0.24853191,\n",
       " 0.6560779,\n",
       " 0.6261018,\n",
       " 0.68756676,\n",
       " 0.33251557,\n",
       " 0.0040147887,\n",
       " 0.4886038,\n",
       " 0.5464401,\n",
       " 0.9833692,\n",
       " 0.5462222,\n",
       " 0.001341001,\n",
       " 0.62846214,\n",
       " 0.56124246,\n",
       " 0.123144075,\n",
       " 0.7937774,\n",
       " 0.030351363,\n",
       " 0.4821569,\n",
       " 0.52804196,\n",
       " 0.08669495,\n",
       " 0.00860774,\n",
       " 0.22728018,\n",
       " 0.7952757,\n",
       " 0.43774092,\n",
       " 0.7125111,\n",
       " 0.5169423,\n",
       " 0.012030124,\n",
       " 0.48982587,\n",
       " 0.71190405,\n",
       " 0.66217923,\n",
       " 0.8402968,\n",
       " 0.91814137,\n",
       " 0.0049239756,\n",
       " 0.14750254,\n",
       " 0.66130996,\n",
       " 0.77849764,\n",
       " 0.035546962,\n",
       " 0.005940852,\n",
       " 0.024453714,\n",
       " 0.65384585,\n",
       " 0.0005094791,\n",
       " 0.57649183,\n",
       " 0.0473223,\n",
       " 0.0030707843,\n",
       " 0.5060326,\n",
       " 0.82691807,\n",
       " 0.012507538,\n",
       " 0.022141838,\n",
       " 0.2020795,\n",
       " 0.4275215,\n",
       " 0.5628512,\n",
       " 0.6034178,\n",
       " 0.17942512,\n",
       " 0.0011211039,\n",
       " 0.0076525267,\n",
       " 0.37995648,\n",
       " 0.095814064,\n",
       " 0.699509,\n",
       " 0.010233734,\n",
       " 0.46641478,\n",
       " 0.0024287088,\n",
       " 0.9099774,\n",
       " 0.075309984,\n",
       " 0.031721115,\n",
       " 0.8090853,\n",
       " 0.62728214,\n",
       " 0.18730083,\n",
       " 0.72450393,\n",
       " 0.02536056,\n",
       " 0.023764437,\n",
       " 0.7970524,\n",
       " 0.85053337,\n",
       " 0.010428136,\n",
       " 0.6133032,\n",
       " 0.47426555,\n",
       " 0.73662096,\n",
       " 0.67816144,\n",
       " 0.010287548,\n",
       " 0.51720685,\n",
       " 0.80058455,\n",
       " 0.047079694,\n",
       " 0.007735963,\n",
       " 0.7807297,\n",
       " 0.20903975,\n",
       " 0.88001305,\n",
       " 0.54638803,\n",
       " 0.32463035,\n",
       " 0.7424253,\n",
       " 0.014574051,\n",
       " 0.0037531382,\n",
       " 0.13761216,\n",
       " 0.25931165,\n",
       " 0.49328166,\n",
       " 0.025463292,\n",
       " 0.4202627,\n",
       " 0.62718797,\n",
       " 0.0056052026,\n",
       " 0.10057412,\n",
       " 0.85324913,\n",
       " 0.004430704,\n",
       " 0.68912053,\n",
       " 0.015000587,\n",
       " 0.45484272,\n",
       " 0.0142095685,\n",
       " 0.0044770916,\n",
       " 0.45299506,\n",
       " 0.36025146,\n",
       " 0.74747753,\n",
       " 0.57585055,\n",
       " 0.007898771,\n",
       " 0.041101497,\n",
       " 0.028215418,\n",
       " 0.73953605,\n",
       " 0.4745564,\n",
       " 0.05736159,\n",
       " 0.1253992,\n",
       " 0.008330506,\n",
       " 0.5928004,\n",
       " 0.47864696,\n",
       " 0.023050448,\n",
       " 0.7010421,\n",
       " 0.50147885,\n",
       " 0.5563096,\n",
       " 0.0037896424,\n",
       " 0.09693772,\n",
       " 0.004164041,\n",
       " 0.34385744,\n",
       " 0.98646533,\n",
       " 0.6679665,\n",
       " 0.5884269,\n",
       " 0.49624237,\n",
       " 0.22425778,\n",
       " 0.54157186,\n",
       " 0.3380942,\n",
       " 0.003977667,\n",
       " 0.005994221,\n",
       " 0.071154214,\n",
       " 0.19845705,\n",
       " 0.08243828,\n",
       " 0.5164009,\n",
       " 0.25473267,\n",
       " 0.3827229,\n",
       " 0.58571374,\n",
       " 0.003417599,\n",
       " 0.69630915,\n",
       " 0.029229056,\n",
       " 0.6571033,\n",
       " 0.015134318,\n",
       " 0.007086326,\n",
       " 0.0002641809,\n",
       " 0.55696815,\n",
       " 0.018114302,\n",
       " 0.4172647,\n",
       " 0.7662125,\n",
       " 0.4197985,\n",
       " 0.5930397,\n",
       " 0.0031836608,\n",
       " 0.8904084,\n",
       " 0.37593314,\n",
       " 0.12796818,\n",
       " 0.6560208,\n",
       " 0.005551649,\n",
       " 0.18616654,\n",
       " 0.0050307093,\n",
       " 0.5918027,\n",
       " 0.028676687,\n",
       " 0.00082826696,\n",
       " 0.0038141988,\n",
       " 0.0059065456,\n",
       " 0.8936324,\n",
       " 0.69367963,\n",
       " 0.30958638,\n",
       " 0.64020985,\n",
       " 0.00986147,\n",
       " 0.0073278407,\n",
       " 0.7992255,\n",
       " 0.53707105,\n",
       " 0.021508899,\n",
       " 0.012414574,\n",
       " 0.5030708,\n",
       " 0.72325397,\n",
       " 0.45749897,\n",
       " 0.0400524,\n",
       " 0.0038888983,\n",
       " 0.007135353,\n",
       " 0.7075404,\n",
       " 0.12412777,\n",
       " 0.29376397,\n",
       " 0.019359076,\n",
       " 0.8701268,\n",
       " 0.0049344953,\n",
       " 0.024055343,\n",
       " 0.7992158,\n",
       " 0.0031441734,\n",
       " 0.5652841,\n",
       " 0.012846586,\n",
       " 0.0843721,\n",
       " 0.37177292,\n",
       " 0.13652374,\n",
       " 0.0076831235,\n",
       " 0.008688068,\n",
       " 0.006038829,\n",
       " 0.0061748093,\n",
       " 0.6099538,\n",
       " 0.33690104,\n",
       " 0.0033142255,\n",
       " 0.5852168,\n",
       " 0.5748082,\n",
       " 0.0068429736,\n",
       " 0.55430293,\n",
       " 0.49544722,\n",
       " 0.8443244,\n",
       " 0.32908598,\n",
       " 0.13347305,\n",
       " 0.51469797,\n",
       " 0.5192367,\n",
       " 0.0046968316,\n",
       " 0.0044080913,\n",
       " 0.6126879,\n",
       " 0.21933089,\n",
       " 0.0025013587,\n",
       " 0.38802513,\n",
       " 0.4709984,\n",
       " 0.43342537,\n",
       " 0.45409983,\n",
       " 0.013247732,\n",
       " 0.21585165,\n",
       " 0.4635005,\n",
       " 0.027737685,\n",
       " 0.25547495,\n",
       " 0.02732017,\n",
       " 0.81330955,\n",
       " 0.008330577,\n",
       " 0.45774025,\n",
       " 0.011554565,\n",
       " 0.66588473,\n",
       " 0.6110183,\n",
       " 0.004035729,\n",
       " 0.32291266,\n",
       " 0.68385607,\n",
       " 0.000929962,\n",
       " 0.0137793105,\n",
       " 0.091681406,\n",
       " 0.46219856,\n",
       " 0.05007371,\n",
       " 0.006705394,\n",
       " 0.024464354,\n",
       " 0.65779847,\n",
       " 0.0027605796,\n",
       " 0.9878249,\n",
       " 0.3959981,\n",
       " 0.4259632,\n",
       " 0.3883735,\n",
       " 0.3551206,\n",
       " 0.004542044,\n",
       " 0.13347305,\n",
       " 0.36989728,\n",
       " 0.005689278,\n",
       " 0.88125074,\n",
       " 0.66744184,\n",
       " 0.15004908,\n",
       " 0.48717925,\n",
       " 0.20400454,\n",
       " 0.6739222,\n",
       " 0.0076446366,\n",
       " 0.032292824,\n",
       " 0.015900504,\n",
       " 0.1544801,\n",
       " 0.010764959,\n",
       " 0.15961316,\n",
       " 0.04255892,\n",
       " 0.40706545,\n",
       " 0.016935946,\n",
       " 0.47572848,\n",
       " 0.023957608,\n",
       " 0.24310629,\n",
       " 0.0010972583,\n",
       " 0.0021972666,\n",
       " 0.003506243,\n",
       " 0.30894843,\n",
       " 0.007011908,\n",
       " 0.26307526,\n",
       " 0.35485527,\n",
       " 0.008210575,\n",
       " 0.18960562,\n",
       " 0.011065093,\n",
       " 0.6117588,\n",
       " 0.77955186,\n",
       " 0.0059280647,\n",
       " 0.82681125,\n",
       " 0.33858287,\n",
       " 0.56309044,\n",
       " 0.6346974,\n",
       " 0.025386266,\n",
       " 0.57098424,\n",
       " 0.001780732,\n",
       " 0.5213176,\n",
       " 0.58786076,\n",
       " 0.0019160843,\n",
       " 0.0022110625,\n",
       " 0.015074378,\n",
       " 0.19727273,\n",
       " 0.0058826106,\n",
       " 0.60953367,\n",
       " 0.00016807723,\n",
       " 0.7296089,\n",
       " 0.63435364,\n",
       " 0.4673993,\n",
       " 0.56060123,\n",
       " 0.028751547,\n",
       " 0.008938323,\n",
       " 0.030222468,\n",
       " 0.9247754,\n",
       " 0.43437263,\n",
       " 0.0029361423,\n",
       " 0.5112424,\n",
       " 0.37956816,\n",
       " 0.02072062,\n",
       " 0.13709486,\n",
       " 0.20934504,\n",
       " 0.013584604,\n",
       " 0.015879178,\n",
       " 0.36706805,\n",
       " 0.0017918294,\n",
       " 0.02190797,\n",
       " 0.5232318,\n",
       " 0.0013452715,\n",
       " 0.5809283,\n",
       " 0.53774875,\n",
       " 0.74650764,\n",
       " 0.830685,\n",
       " 0.43999118,\n",
       " 0.094928525,\n",
       " 0.78119284,\n",
       " 0.8506391,\n",
       " 0.0014839387,\n",
       " 0.013090994,\n",
       " 0.38383952,\n",
       " 0.048592843,\n",
       " 0.006965501,\n",
       " 0.051517796,\n",
       " 0.05573248,\n",
       " 0.040548086,\n",
       " 0.6852271,\n",
       " 0.5977687,\n",
       " 0.0010072164,\n",
       " 0.38430038,\n",
       " 0.0039481022,\n",
       " 0.0019040493,\n",
       " 0.6428348,\n",
       " 0.68509674,\n",
       " 0.0014579452,\n",
       " 0.3705958,\n",
       " 0.6446152,\n",
       " 0.58181375,\n",
       " 0.0020877896,\n",
       " 0.03265281,\n",
       " 0.84821147,\n",
       " 0.6807396,\n",
       " 0.000612221,\n",
       " 0.008891444,\n",
       " 0.27070823,\n",
       " 0.0014827993,\n",
       " 0.0014759465,\n",
       " 0.0016583934,\n",
       " 0.46347833,\n",
       " 0.008775217,\n",
       " 0.84593827,\n",
       " 0.29518625,\n",
       " 0.0054699983,\n",
       " 0.0028279568,\n",
       " 0.01329604,\n",
       " 0.6463409,\n",
       " 0.90575427,\n",
       " 0.7245551,\n",
       " 0.005487247,\n",
       " 0.021582693,\n",
       " 0.034214385,\n",
       " 0.5669246,\n",
       " 0.45275146,\n",
       " 0.49306664,\n",
       " 0.6679665,\n",
       " 0.023086779,\n",
       " 0.041827682,\n",
       " 0.003889805,\n",
       " 0.005521598,\n",
       " 0.62411284,\n",
       " 0.0030948573,\n",
       " 0.005855873,\n",
       " 0.48506796,\n",
       " 0.37969851,\n",
       " 0.0010032309,\n",
       " 0.6875009,\n",
       " 0.011141423,\n",
       " 0.0013499523,\n",
       " 0.44510353,\n",
       " 0.61377865,\n",
       " 0.2700699,\n",
       " 0.009803159,\n",
       " 0.78590095,\n",
       " 0.01955109,\n",
       " 0.69769615,\n",
       " 0.42687067,\n",
       " 0.01840235,\n",
       " 0.96790767,\n",
       " 0.8118492,\n",
       " 0.7113965,\n",
       " 0.69711024,\n",
       " 0.61860853,\n",
       " 0.11019456,\n",
       " 0.016833909,\n",
       " 0.4132539,\n",
       " 0.7639666,\n",
       " 0.7172042,\n",
       " 0.59496385,\n",
       " 0.69989306,\n",
       " 0.005865163,\n",
       " 0.6851619,\n",
       " 0.0018931682,\n",
       " 0.22439153,\n",
       " 0.0023502056,\n",
       " 0.20498869,\n",
       " 0.44306836,\n",
       " 0.0037445612,\n",
       " 0.29343253,\n",
       " 0.44565657,\n",
       " 0.8430836,\n",
       " 0.35052913,\n",
       " 0.00556965,\n",
       " 0.022875575,\n",
       " 0.0015547118,\n",
       " 0.0028326104,\n",
       " 0.2717358,\n",
       " 0.49079195,\n",
       " 0.41778,\n",
       " 0.5913717,\n",
       " 0.010480123,\n",
       " 0.0076303394,\n",
       " 0.7802462,\n",
       " 0.0056763636,\n",
       " 0.0013698009,\n",
       " 0.12370756,\n",
       " 0.009582266,\n",
       " 0.02036199,\n",
       " 0.7331941,\n",
       " 0.67879355,\n",
       " 0.5873851,\n",
       " 0.01232018,\n",
       " 0.54485357,\n",
       " 0.0039308416,\n",
       " 0.019702148,\n",
       " 0.4368913,\n",
       " 0.4633967,\n",
       " 0.012990223,\n",
       " 0.0071900836,\n",
       " 0.0043774545,\n",
       " 0.00395873,\n",
       " 0.061215743,\n",
       " 0.3729093,\n",
       " 0.2825384,\n",
       " 0.0052083945,\n",
       " 0.0028306232,\n",
       " 0.010571651,\n",
       " 0.52957827,\n",
       " 0.7156359,\n",
       " 0.40996832,\n",
       " 0.4151922,\n",
       " 0.06438354,\n",
       " 0.8065863,\n",
       " 0.004290326,\n",
       " 0.33030528,\n",
       " 0.009254489,\n",
       " 0.57708216,\n",
       " 0.0011586254,\n",
       " 0.014519906,\n",
       " 0.15477362,\n",
       " 0.71182877,\n",
       " 0.6110486,\n",
       " 0.86756337,\n",
       " 0.5262597,\n",
       " 0.41761905,\n",
       " 0.007668204,\n",
       " 0.28643778,\n",
       " 0.75011075,\n",
       " 0.014408742,\n",
       " 0.5299092,\n",
       " 0.0034623884,\n",
       " 0.74750173,\n",
       " 0.0027956285,\n",
       " 0.9665109,\n",
       " 0.13829507,\n",
       " 0.011395336,\n",
       " 0.0014035157,\n",
       " 0.0013930154,\n",
       " 0.04381461,\n",
       " 0.8129888,\n",
       " 0.0024059173,\n",
       " 0.13852689,\n",
       " 0.44296953,\n",
       " 0.49976188,\n",
       " 0.80857325,\n",
       " 0.44152033,\n",
       " 0.0016678966,\n",
       " 0.69769615,\n",
       " 0.62124044,\n",
       " 0.016363291,\n",
       " 0.24318725,\n",
       " 0.0028222129,\n",
       " 0.011334655,\n",
       " 0.48973832,\n",
       " 0.2387895,\n",
       " 0.70390594,\n",
       " 0.33469144,\n",
       " 0.36571074,\n",
       " 0.013057382,\n",
       " 0.65774536,\n",
       " 0.0049245427,\n",
       " 0.0027861358,\n",
       " 0.7672063,\n",
       " 0.0047081043,\n",
       " 0.5449465,\n",
       " 0.3914685,\n",
       " 0.37000817,\n",
       " 0.43909872,\n",
       " 0.012543975,\n",
       " 0.53774875,\n",
       " 0.4202627,\n",
       " 0.6686271,\n",
       " 0.3622037,\n",
       " 0.0050706705,\n",
       " 0.0007477019,\n",
       " 0.6101873,\n",
       " 0.38621858,\n",
       " 0.7816309,\n",
       " 0.6963597,\n",
       " 0.0025418256,\n",
       " 0.4770486,\n",
       " 0.90458953,\n",
       " 0.002928011,\n",
       " 0.0069150147,\n",
       " 0.41481984,\n",
       " 0.39045584,\n",
       " 0.0019229018,\n",
       " 0.54545826,\n",
       " 0.0010626637,\n",
       " 0.03458655,\n",
       " 0.11371576,\n",
       " 0.010829461,\n",
       " 0.0016210143,\n",
       " 0.024239225,\n",
       " 0.39235148,\n",
       " 0.5942468,\n",
       " 0.52832526,\n",
       " 0.8526094,\n",
       " 0.52105856,\n",
       " 0.55080724,\n",
       " 0.3115133,\n",
       " 0.37374514,\n",
       " 0.014547237,\n",
       " 0.871053,\n",
       " 0.058001768,\n",
       " 0.65940493,\n",
       " 0.0034458714,\n",
       " 0.0078282785,\n",
       " 0.8187487,\n",
       " 0.0085315835,\n",
       " 0.006613046,\n",
       " 0.109005466,\n",
       " 0.66167206,\n",
       " 0.76276124,\n",
       " 0.14313677,\n",
       " 0.71536654,\n",
       " 0.4355138,\n",
       " 0.45282507,\n",
       " 0.007620983,\n",
       " 0.0014694121,\n",
       " 0.26484948,\n",
       " 0.4852024,\n",
       " 0.0031781693,\n",
       " 0.12338052,\n",
       " 0.04956662,\n",
       " 0.6496937,\n",
       " 0.8145521,\n",
       " 0.23131768,\n",
       " 0.7423392,\n",
       " 0.447291,\n",
       " 0.79763395,\n",
       " 0.76442724,\n",
       " 0.0062338994,\n",
       " 0.5170592,\n",
       " 0.005993798,\n",
       " 0.009998974,\n",
       " 0.25367802,\n",
       " 0.3750125,\n",
       " 0.014305341,\n",
       " 0.43292958,\n",
       " 0.6967296,\n",
       " 0.69145095,\n",
       " 0.33058435,\n",
       " 0.0041672452,\n",
       " 0.73726565,\n",
       " 0.109106705,\n",
       " 0.46693778,\n",
       " 0.01378029,\n",
       " 0.013189136,\n",
       " 0.5655123,\n",
       " 0.75006574,\n",
       " 0.8556598,\n",
       " 0.005429206,\n",
       " 0.326008,\n",
       " 0.830685,\n",
       " 0.5904365,\n",
       " 0.2867329,\n",
       " 0.62194806,\n",
       " 0.45142087,\n",
       " 0.78373593,\n",
       " 0.6779852,\n",
       " 0.019627212,\n",
       " 0.77944255,\n",
       " 0.6089991,\n",
       " 0.015396791,\n",
       " 0.0032998382,\n",
       " 0.6098481,\n",
       " 0.45443302,\n",
       " 0.017534913,\n",
       " 0.01560398,\n",
       " 0.7393628,\n",
       " 0.025321765,\n",
       " 0.011118578,\n",
       " 0.62688804,\n",
       " 0.6917174,\n",
       " 0.009288522,\n",
       " 0.6763941,\n",
       " 0.8412948,\n",
       " 0.6383473,\n",
       " 0.505812,\n",
       " 0.006617417,\n",
       " 0.012842712,\n",
       " 0.28268418,\n",
       " 0.030895704,\n",
       " 0.24350548,\n",
       " 0.6007447,\n",
       " 0.22249372,\n",
       " 0.007702937,\n",
       " 0.6473751,\n",
       " 0.049759623,\n",
       " 0.015220565,\n",
       " 0.6646707,\n",
       " 0.6756255,\n",
       " 0.7913513,\n",
       " 0.6906263,\n",
       " 0.00394799,\n",
       " 0.09765206,\n",
       " 0.76621616,\n",
       " 0.674288,\n",
       " 0.559284,\n",
       " 0.006203614,\n",
       " 0.08697175,\n",
       " 0.0042082183,\n",
       " 0.006518499,\n",
       " 0.39209738,\n",
       " 0.30793077,\n",
       " 0.79922026,\n",
       " 0.018928014,\n",
       " 0.55338544,\n",
       " 0.010359177,\n",
       " 0.6763163,\n",
       " 0.0057830694,\n",
       " 0.019203512,\n",
       " 0.028787227,\n",
       " 0.56280994,\n",
       " 0.795303,\n",
       " 0.49713415,\n",
       " 0.013508223,\n",
       " 0.008338676,\n",
       " 0.27558318,\n",
       " 0.012514159,\n",
       " 0.006648065,\n",
       " 0.00060812,\n",
       " 0.3669673,\n",
       " 0.79991657,\n",
       " 0.0058546546,\n",
       " 0.005285552,\n",
       " 0.049719147,\n",
       " 0.089205295,\n",
       " 0.024039509,\n",
       " 0.79090184,\n",
       " 0.0021429933,\n",
       " 0.50997496,\n",
       " 0.41290104,\n",
       " 0.78376377,\n",
       " 0.26413363,\n",
       " 0.051024936,\n",
       " 0.004477083,\n",
       " 0.0014534647,\n",
       " 0.060257558,\n",
       " 0.92760384,\n",
       " 0.005725198,\n",
       " 0.028652364,\n",
       " 0.27498674,\n",
       " 0.0025255207,\n",
       " 0.52706575,\n",
       " 0.32114655,\n",
       " 0.7399504,\n",
       " 0.5060497,\n",
       " 0.68549657,\n",
       " 0.010226835,\n",
       " 0.1955449,\n",
       " 0.51342386,\n",
       " 0.44311985,\n",
       " 0.45644245,\n",
       " 0.57738286,\n",
       " 0.61770076,\n",
       " 0.83782625,\n",
       " 0.00053702266,\n",
       " 0.012968775,\n",
       " 0.026066896,\n",
       " 0.012214977,\n",
       " 0.026851993,\n",
       " 0.7469201,\n",
       " 0.970676,\n",
       " 0.0063338415,\n",
       " 0.28708714,\n",
       " 0.7537568,\n",
       " 0.123410575,\n",
       " 0.024153525,\n",
       " 0.37112874,\n",
       " 0.025443856,\n",
       " 0.0066842088,\n",
       " 0.30387476,\n",
       " 0.010078933,\n",
       " 0.75423265,\n",
       " 0.5023963,\n",
       " 0.59466606,\n",
       " 0.029788306,\n",
       " 0.45703202,\n",
       " 0.54908985,\n",
       " 0.0022337225,\n",
       " 0.6355005,\n",
       " 0.0022253024,\n",
       " 0.009787674,\n",
       " 0.0025517363,\n",
       " 0.36553395,\n",
       " 0.0061988714,\n",
       " 0.51653147,\n",
       " 0.6038209,\n",
       " 0.010374049,\n",
       " 0.23187265,\n",
       " 0.73642147,\n",
       " 0.68132627,\n",
       " 0.47635567,\n",
       " 0.5212717,\n",
       " 0.677663,\n",
       " 0.67317605,\n",
       " 0.3572234,\n",
       " 0.49434248,\n",
       " 0.7814358,\n",
       " 0.0031992884,\n",
       " 0.362966,\n",
       " 0.71085536,\n",
       " 0.0059022713,\n",
       " 0.18439959,\n",
       " 0.47350782,\n",
       " 0.0051147025,\n",
       " 0.8003427,\n",
       " 0.6235056,\n",
       " 0.035315543,\n",
       " 0.0010764899,\n",
       " 0.382202,\n",
       " 0.010225025,\n",
       " 0.0013103891,\n",
       " 0.53230816,\n",
       " 0.7394666,\n",
       " 0.78415334,\n",
       " 0.017182386,\n",
       " 0.20346026,\n",
       " 0.23164953,\n",
       " 0.57738286,\n",
       " 0.45142087,\n",
       " 0.76123744,\n",
       " 0.05898318,\n",
       " 0.44995943,\n",
       " 0.28707567,\n",
       " 0.8658319,\n",
       " 0.58704704,\n",
       " 0.0004121994,\n",
       " 0.42289475,\n",
       " 0.0038211476,\n",
       " 0.56787586,\n",
       " 0.52145076,\n",
       " 0.44842225,\n",
       " 0.033377122,\n",
       " 0.43269783,\n",
       " 0.031453487,\n",
       " 0.0022988643,\n",
       " 0.84475535,\n",
       " 0.77145183,\n",
       " 0.7872627,\n",
       " 0.73857975,\n",
       " 0.06270186,\n",
       " 0.043775793,\n",
       " 0.0033333565,\n",
       " 0.6316962,\n",
       " 0.8492473,\n",
       " 0.7394525,\n",
       " 0.012213159,\n",
       " 0.53368986,\n",
       " 0.7984069,\n",
       " 0.013751487,\n",
       " 0.010680302,\n",
       " 0.794279,\n",
       " 0.009944044,\n",
       " 0.06955866,\n",
       " 0.0016650755,\n",
       " 0.640397,\n",
       " 0.64799374,\n",
       " 0.03883363,\n",
       " 0.41969547,\n",
       " 0.6521898,\n",
       " 0.16333568,\n",
       " 0.0025977707,\n",
       " 0.10999659,\n",
       " 0.18266173,\n",
       " 0.6680721,\n",
       " 0.7132712,\n",
       " 0.5567269,\n",
       " 0.34619093,\n",
       " 0.002649466,\n",
       " 0.6006929,\n",
       " 0.3333761,\n",
       " 0.016849164,\n",
       " 0.12025976,\n",
       " 0.37694743,\n",
       " 0.72009194,\n",
       " 0.7105307,\n",
       " 0.03100927,\n",
       " 0.020496173,\n",
       " 0.4567189,\n",
       " 0.25557777,\n",
       " 0.006985705,\n",
       " 0.57641166,\n",
       " 0.09807464,\n",
       " 0.21714827,\n",
       " 0.0068887407,\n",
       " 0.05527613,\n",
       " 0.0059736553,\n",
       " 0.033276826,\n",
       " 0.80331147,\n",
       " 0.58864415,\n",
       " 0.0012284665,\n",
       " 0.4649019,\n",
       " 0.59183186,\n",
       " 0.7464736,\n",
       " 0.83406246,\n",
       " 0.069722794,\n",
       " 0.32142502,\n",
       " 0.40951195,\n",
       " 0.004955958,\n",
       " 0.75086546,\n",
       " 0.026525833,\n",
       " 0.47806638,\n",
       " 0.5688292,\n",
       " 0.117961496,\n",
       " 0.5321242,\n",
       " 0.5892161,\n",
       " 0.68558216,\n",
       " 0.8153661,\n",
       " 0.36492535,\n",
       " 0.009877826,\n",
       " 0.0041136686,\n",
       " 0.005556126,\n",
       " 0.56428117,\n",
       " 0.55784184,\n",
       " 0.0003260989,\n",
       " 0.27973968,\n",
       " 0.020986428,\n",
       " 0.00010637763,\n",
       " 0.4273919,\n",
       " 0.63518405,\n",
       " 0.9356823,\n",
       " 0.010571726,\n",
       " 0.0010003914,\n",
       " 0.5235082,\n",
       " 0.6843151,\n",
       " 0.008813162,\n",
       " 0.81560475,\n",
       " 0.67248493,\n",
       " 0.002068162,\n",
       " 0.45249122,\n",
       " 0.28187403,\n",
       " 0.019230869,\n",
       " 0.39842474,\n",
       " 0.86823833,\n",
       " 0.44211134,\n",
       " 0.47711363,\n",
       " 0.0051228176,\n",
       " 0.008939932,\n",
       " 0.53983647,\n",
       " 0.51142794,\n",
       " 0.035983305,\n",
       " 0.8171936,\n",
       " 0.6481428,\n",
       " 0.47122976,\n",
       " 0.9106479,\n",
       " 0.004757979,\n",
       " 0.107892655,\n",
       " 0.39955163,\n",
       " 0.6338931,\n",
       " 0.06556712,\n",
       " 0.8145957,\n",
       " 0.0019837099,\n",
       " 0.52443033,\n",
       " 0.62248445,\n",
       " 0.7152545,\n",
       " 0.69592375,\n",
       " 0.64291656,\n",
       " 0.7679166,\n",
       " 0.0192878,\n",
       " 0.019070094,\n",
       " 0.80940056,\n",
       " 0.604563,\n",
       " 0.0012362165,\n",
       " 0.0006859067,\n",
       " 0.48933372,\n",
       " 0.004343615,\n",
       " 0.34248477,\n",
       " 0.0021053946,\n",
       " 0.831555,\n",
       " 0.24198686,\n",
       " 0.70181996,\n",
       " 0.6626755,\n",
       " 0.6639799,\n",
       " 0.008092058,\n",
       " 0.4463905,\n",
       " 0.67623204,\n",
       " 0.6602141,\n",
       " 0.32563734,\n",
       " 0.00922523,\n",
       " 0.8989588,\n",
       " 0.0030359628,\n",
       " 0.6465246,\n",
       " 0.020817336,\n",
       " 0.80026674,\n",
       " 0.09421934,\n",
       " 0.24104899,\n",
       " 0.0016502449,\n",
       " 0.04932462,\n",
       " 0.16478036,\n",
       " 0.008006008,\n",
       " 0.47948164,\n",
       " 0.0042850473,\n",
       " 0.35768917,\n",
       " 0.10634946,\n",
       " 0.56377137,\n",
       " 0.009255107,\n",
       " 0.7185065,\n",
       " 0.67591053,\n",
       " 0.0044332263,\n",
       " 0.33955932,\n",
       " ...]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_array=[]\n",
    "for i in y_pro:\n",
    "    Test_array.append(i[1])\n",
    "Test_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33637233723630783\n"
     ]
    }
   ],
   "source": [
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)\n",
    "average = Average(Test_array)\n",
    "print(average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99837327"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pro[1][0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 1], dtype=uint8)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_te_pred=xg_gb.predict(x_te)\n",
    "y_te_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36213652299443183"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_te_pred.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0], dtype=uint8)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_te_pred[1:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0016267279,\n",
       " 0.0041177203,\n",
       " 0.098133914,\n",
       " 0.34862465,\n",
       " 0.0018365277,\n",
       " 0.458429,\n",
       " 0.72252584,\n",
       " 0.0059563913,\n",
       " 0.99586546,\n",
       " 0.01722325]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_array[1:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,roc_auc_score,f1_score,precision_score,recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score =0.7728112301440709, roc auc score =0.7831686435258967\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy score ={accuracy_score(y_tr,xg_gb.predict(x_tr))}, roc auc score ={roc_auc_score(y_tr,xg_gb.predict(x_tr))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score =0.7103838003296444, precision =0.6290658882402002, recall =0.8158464034613304\n"
     ]
    }
   ],
   "source": [
    "print(f'f1 score ={f1_score(y_tr,xg_gb.predict(x_tr))}, precision ={precision_score(y_tr,xg_gb.predict(x_tr))}, recall ={recall_score(y_tr,xg_gb.predict(x_tr))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score =0.7467191601049868, roc auc score =0.7541546086060202\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy score ={accuracy_score(y_te,xg_gb.predict(x_te))}, roc auc score ={roc_auc_score(y_te,xg_gb.predict(x_te))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score =0.6770260578532153, precision =0.5994919559695173, recall =0.7775947281713345\n"
     ]
    }
   ],
   "source": [
    "print(f'f1 score ={f1_score(y_te,xg_gb.predict(x_te))}, precision ={precision_score(y_te,xg_gb.predict(x_te))}, recall ={recall_score(y_te,xg_gb.predict(x_te))}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
